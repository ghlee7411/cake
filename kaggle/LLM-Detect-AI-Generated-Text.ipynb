{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Team JelyTooth] LLM - Detect AI Generated Text\n",
    "- Competition: [Detect AI Generated Text](https://www.kaggle.com/competitions/llm-detect-ai-generated-text/overview)\n",
    "- Timeline\n",
    "    - October 31, 2023 - Start Date.\n",
    "    - January 15, 2024 - Entry Deadline. You must accept the competition rules before this date in order to compete.\n",
    "    - January 15, 2024 - Team Merger Deadline. This is the last day participants may join or merge teams.\n",
    "    - January 22, 2024 - Final Submission Deadline.\n",
    "\n",
    "### Original sources üëç\n",
    "<!-- Drawing Table here, Leftside aligned -->\n",
    "| Name | Type | Description | Link |\n",
    "|:---|:---|:---|:---|\n",
    "| üååüé≤ Token Game: Ensemble Playbook üìñüîÆ | Notebook | BPE, Sentencepiece ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†ÄÏôÄ Í∏∞Î≥∏Ï†ÅÏù∏ ML ClassifierÏùò EnsembleÏùÑ ÌÜµÌï¥ ÌÖçÏä§Ìä∏Î•º Î∂ÑÎ•òÌïòÎäî Î∞©Î≤ïÏùÑ ÏÜåÍ∞úÌïòÎäî ÎÖ∏Ìä∏Î∂Å ÏòàÏãú. Ï†êÏàòÍ∞Ä 0.96ÏúºÎ°ú ÎÜíÏùÄ ÏÑ±Îä•ÏùÑ Î≥¥Ïó¨Ï§å. | [Link](https://www.kaggle.com/code/verracodeguacas/token-game-ensemble-playbook) |\n",
    "| DAIGT V2 Train Dataset | Dataset | A dataset you can actually train on for the LLM Detect AI Generated Text comp. DAIGT ÎåÄÌöå Ï∞∏Í∞ÄÏûêÎì§Ïù¥ ÏÉùÏÑ±Ìïú Îç∞Ïù¥ÌÑ∞ ÏÑ∏Ìä∏Î•º ÌÜµÌï©Ìï¥ÏÑú Ï†úÍ≥µÌïòÎäî Îç∞Ïù¥ÌÑ∞ÏÑ∏Ìä∏. | [Link](https://www.kaggle.com/datasets/thedrcat/daigt-v2-train-dataset) |\n",
    "| Text generated with ChatGPT by MOTH | Dataset | Text generated with ChatGPT by MOTH | [Link](https://www.kaggle.com/datasets/alejopaullier/daigt-external-dataset) |\n",
    "| Persuade corpus contributed by Nicholas Broad | Dataset | Persuade corpus contributed by Nicholas Broad | [Link](https://www.kaggle.com/datasets/nbroad/persaude-corpus-2/) |\n",
    "| Text generated with Llama-70b and Falcon180b by Nicholas Broad | Dataset | Text generated with Llama-70b and Falcon180b by Nicholas Broad | [Link](https://www.kaggle.com/datasets/nbroad/daigt-data-llama-70b-and-falcon180b) |\n",
    "| Text generated with ChatGPT and GPT4 by Radek | Dataset | Text generated with ChatGPT and GPT4 by Radek | [Link](https://www.kaggle.com/datasets/radek1/llm-generated-essays) |\n",
    "| 2000 Claude essays generated by @darraghdog | Dataset | 2000 Claude essays generated by @darraghdog | [Link](https://www.kaggle.com/datasets/darraghdog/hello-claude-1000-essays-from-anthropic) |\n",
    "| LLM-generated essay using PaLM from Google Gen-AI by @kingki19 | Dataset | LLM-generated essay using PaLM from Google Gen-AI by @kingki19 | [Link](https://www.kaggle.com/datasets/kingki19/llm-generated-essay-using-palm-from-google-gen-ai) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import gc\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tokenizers import (\n",
    "    decoders,\n",
    "    models,\n",
    "    normalizers,\n",
    "    pre_tokenizers,\n",
    "    processors,\n",
    "    trainers,\n",
    "    Tokenizer,\n",
    "    SentencePieceBPETokenizer\n",
    ")\n",
    "from datasets import Dataset\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from typing import List\n",
    "import logging\n",
    "\n",
    "\n",
    "def create_logger(name: str):\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    return logger\n",
    "\n",
    "logger = create_logger('LLM-Detect-AI-Generated-Text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "LOWERCASE = False\n",
    "VOCAB_SIZE = 64000\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ÎåÄÌöå Ï∞∏Í∞ÄÏö© Îç∞Ïù¥ÌÑ∞\n",
    "ÎåÄÌöå Îç∞Ïù¥ÌÑ∞Îäî Kaggle APIÎ•º ÌÜµÌï¥ Îç∞Ïù¥ÌÑ∞Î•º Îã§Ïö¥Î°úÎìú Î∞õÏùÑ Ïàò ÏûàÏäµÎãàÎã§.\n",
    "```bash\n",
    "kaggle competitions download -c llm-detect-ai-generated-text\n",
    "unzip llm-detect-ai-generated-text.zip\n",
    "ls\n",
    "```\n",
    "Îã§Ïö¥Î°úÎìú Î∞õÏùÄ Îç∞Ïù¥ÌÑ∞Îäî Îã§ÏùåÍ≥º Í∞ôÏäµÎãàÎã§.\n",
    "```\n",
    "sample_submission.csv  test_essays.csv train_essays.csv train_prompts.csv\n",
    "```\n",
    "\n",
    "### ÌïôÏäµÏö© Îç∞Ïù¥ÌÑ∞ DAIGT V2 Train Dataset\n",
    "Í≥µÍ∞úÎêòÏñ¥ÏûàÎäî DAIGT Îç∞Ïù¥ÌÑ∞ ÏÑ∏Ìä∏Îäî [Ìï¥Îãπ ÎßÅÌÅ¨](https://www.kaggle.com/datasets/thedrcat/daigt-v2-train-dataset)ÏóêÏÑú Îã§Ïö¥Î°úÎìú Î∞õÏùÑ Ïàò ÏûàÏäµÎãàÎã§.\n",
    "\n",
    "> ÎßåÏïΩ Kaggle Notebook ÌôòÍ≤ΩÏóêÏÑú ÏßÑÌñâÌïúÎã§Î©¥ Îç∞Ïù¥ÌÑ∞ ÏÑ∏Ìä∏Î•º Ï∂îÍ∞ÄÌïòÏó¨ ÏÇ¨Ïö©Ìï† Ïàò ÏûàÏäµÎãàÎã§. Ïù¥ Í≤ΩÏö∞ÏóêÎäî Îã§ÏùåÍ≥º Í∞ôÏù¥ Îç∞Ïù¥ÌÑ∞Î•º Îã§Ïö¥Î°úÎìú Î∞õÏùÑ ÌïÑÏöîÍ∞Ä ÏóÜÏäµÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:LLM-Detect-AI-Generated-Text:train_v2_drcat_df shape: (44868, 5)\n",
      "INFO:LLM-Detect-AI-Generated-Text:train_essays_df shape: (1378, 4)\n",
      "INFO:LLM-Detect-AI-Generated-Text:train_prompts_df shape: (2, 4)\n",
      "INFO:LLM-Detect-AI-Generated-Text:test_essays_df shape: (3, 3)\n",
      "INFO:LLM-Detect-AI-Generated-Text:sample_submission_df shape: (3, 2)\n"
     ]
    }
   ],
   "source": [
    "sample_submission_df = pd.read_csv('./dataset/llm-detect-ai-generated-text/sample_submission.csv')\n",
    "test_essays_df = pd.read_csv('./dataset/llm-detect-ai-generated-text/test_essays.csv')\n",
    "train_essays_df = pd.read_csv('./dataset/llm-detect-ai-generated-text/train_essays.csv')\n",
    "train_prompts_df = pd.read_csv('./dataset/llm-detect-ai-generated-text/train_prompts.csv')\n",
    "train_v2_drcat_df = pd.read_csv('./dataset/llm-detect-ai-generated-text/train_v2_drcat_02.csv')\n",
    "\n",
    "# preprocess\n",
    "train_v2_drcat_df = train_v2_drcat_df.drop_duplicates(subset=['text'])\n",
    "train_v2_drcat_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "logger.info('train_v2_drcat_df shape: {}'.format(train_v2_drcat_df.shape))\n",
    "logger.info('train_essays_df shape: {}'.format(train_essays_df.shape))\n",
    "logger.info('train_prompts_df shape: {}'.format(train_prompts_df.shape))\n",
    "logger.info('test_essays_df shape: {}'.format(test_essays_df.shape))\n",
    "logger.info('sample_submission_df shape: {}'.format(sample_submission_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the \"RDizzl3 Seven\"? [Go to discussion](https://www.kaggle.com/competitions/llm-detect-ai-generated-text/discussion/457166)\n",
    "- The \"RDizzl3 Seven\" is a monkier given to the (probable) seven prompts used by the hosts of the competition. \n",
    "- For more detail see the topic \"A \"7 Prompts\" training dataset\" and the comments therein.\n",
    "\n",
    "#### [LLM] A \"7 Prompts\" training dataset [Go to discussion](https://www.kaggle.com/competitions/llm-detect-ai-generated-text/discussion/453410)\n",
    "- DAIGT V2 Train DatasetÏùò Ï†úÏûëÏûêÎäî RDizzl3 Seven ÌïÑÌÑ∞Î•º Ï†ÅÏö©ÌñàÎã§Í≥† Î∞ùÌûò.\n",
    "\n",
    "#### Îç∞Ïù¥ÌÑ∞ ÏÑ∏Ìä∏ ÏàòÏßë Ï†ÑÎûµ?\n",
    "- Ïù¥ÎØ∏ ÎßéÏùÄ ÎåÄÌöå Ï∞∏Í∞ÄÏûêÎì§Ïù¥ Î¨∏Ï†ú Ìï¥Í≤∞ÏùÑ ÏúÑÌïú Îç∞Ïù¥ÌÑ∞Î•º ÏûêÏ≤¥ ÏÉùÏÇ∞ÌïòÍ≥† Í≥µÍ∞úÏ†ÅÏúºÎ°ú ÌÜµÌï©ÌïòÍ≥† ÏûàÏùå\n",
    "- Ïù¥Îü¨Ìïú Í≥µÏú†Îêú Îç∞Ïù¥ÌÑ∞ÏÑ∏Ìä∏Î•º Ï†ÅÍ∑πÏ†ÅÏúºÎ°ú ÌôúÏö©ÌïòÎ©¥ÏÑú ScoringÏùÑ ÎÇº Ïàò ÏûàÎäî Î™®Îç∏ÎßÅÏùÑ Îπ†Î•¥Í≤å ÏàòÌñâ\n",
    "- High scoreÎ•º ÌöçÎìùÌïú Î™®Îç∏ÏóêÏÑú Î∂ÄÏ°±Ìïú Î∂ÄÎ∂ÑÏù¥ Î¨¥ÏóáÏù∏ÏßÄ ÌååÏïÖÌïòÍ≥† Ïù¥Î•º ÏúÑÌïú Îç∞Ïù¥ÌÑ∞Î•º Ï∂îÍ∞ÄÎ°ú ÏàòÏßëÌï¥ private datasetÏùÑ ÎßåÎì§Ïñ¥ Ï†êÏàòÎ•º ÎÜíÏù¥Îäî Î∞©Ìñ•ÏúºÎ°ú ÏßÑÌñâÌïòÎ©¥ Ï¢ãÏùÑ Í≤É Í∞ôÏùå\n",
    "\n",
    "> Í≥µÍ∞ú Îç∞Ïù¥ÌÑ∞ÏÑ∏Ìä∏ ÏàòÏßë -> Î™®Îç∏ÎßÅ (Ï†úÏ∂ú) -> Í∞úÏÑ†Ï†ê ÌååÏïÖ -> Îç∞Ïù¥ÌÑ∞ ÏûêÏ≤¥ ÏÉùÏÇ∞ -> Îç∞Ïù¥ÌÑ∞ÏÑ∏Ìä∏ Ïû¨Í∞ÄÍ≥µ -> Î™®Îç∏ÎßÅ (Ï†úÏ∂ú) -> Í∞úÏÑ†Ï†ê ÌååÏïÖ -> ... Î∞òÎ≥µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>source</th>\n",
       "      <th>RDizzl3_seven</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Phones\\n\\nModern humans today are always on th...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This essay will explain if drivers should or s...</td>\n",
       "      <td>0</td>\n",
       "      <td>Phones and driving</td>\n",
       "      <td>persuade_corpus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  Phones\\n\\nModern humans today are always on th...      0   \n",
       "1  This essay will explain if drivers should or s...      0   \n",
       "\n",
       "          prompt_name           source  RDizzl3_seven  \n",
       "0  Phones and driving  persuade_corpus          False  \n",
       "1  Phones and driving  persuade_corpus          False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_v2_drcat_df.head(2) # ÎßåÏïΩ ÏûêÏ≤¥Ï†ÅÏù∏ Îç∞Ïù¥ÌÑ∞ ÏÑ∏Ìä∏Î•º ÎßåÎì†Îã§Î©¥ Ìï¥Îãπ Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ Íµ¨Ï°∞Ïóê ÎßûÏ∂îÎäî Í≤ÉÏù¥ Î∞îÎûåÏßÅÌï† Í≤É Í∞ôÏäµÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>instructions</th>\n",
       "      <th>source_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "      <td># In German Suburb, Life Goes On Without Cars ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Does the electoral college work?</td>\n",
       "      <td>Write a letter to your state senator in which ...</td>\n",
       "      <td># What Is the Electoral College? by the Office...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prompt_id                       prompt_name  \\\n",
       "0          0                   Car-free cities   \n",
       "1          1  Does the electoral college work?   \n",
       "\n",
       "                                        instructions  \\\n",
       "0  Write an explanatory essay to inform fellow ci...   \n",
       "1  Write a letter to your state senator in which ...   \n",
       "\n",
       "                                         source_text  \n",
       "0  # In German Suburb, Life Goes On Without Cars ...  \n",
       "1  # What Is the Electoral College? by the Office...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prompts_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0059830c</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>005db917</td>\n",
       "      <td>0</td>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  prompt_id                                               text  \\\n",
       "0  0059830c          0  Cars. Cars have been around since they became ...   \n",
       "1  005db917          0  Transportation is a large necessity in most co...   \n",
       "\n",
       "   generated  \n",
       "0          0  \n",
       "1          0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_essays_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>2</td>\n",
       "      <td>Aaa bbb ccc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111bbbb</td>\n",
       "      <td>3</td>\n",
       "      <td>Bbb ccc ddd.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  prompt_id          text\n",
       "0  0000aaaa          2  Aaa bbb ccc.\n",
       "1  1111bbbb          3  Bbb ccc ddd."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_essays_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BPE ÌÜ†ÌÅ¨ÎÇòÏù¥Ïßï / TF-IDF Î≤°ÌÑ∞Ìôî / ML Classifiers Ensemble\n",
    "1. ÌïôÏäµÏö© Îç∞Ïù¥ÌÑ∞ÏÑ∏Ìä∏ÏôÄ ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ÏÑ∏Ìä∏Ïùò ÌÖçÏä§Ìä∏ Ï†ïÎ≥¥Î•º Í∞ÄÏ†∏ÏòµÎãàÎã§.\n",
    "2. ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†ÄÎ•º ÏÇ¨Ïö©ÌïòÏó¨ ÏÑúÎ∏åÌÜ†ÌÅ∞Ìôî ÏãúÌÇµÎãàÎã§.\n",
    "3. Ìï¥Í≤∞ÌïòÎ†§Îäî Î¨∏Ï†úÎäî Ïù∏Í≥µÏ†ÅÏúºÎ°ú ÏÉùÏÑ±Îêú ÌÖçÏä§Ìä∏Î•º ÏãùÎ≥ÑÌïòÎäîÍ≤ÉÏù¥Í∏∞ ÎïåÎ¨∏Ïóê Ïó≠ÏúºÎ°ú ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ÏÑ∏Ìä∏Ïùò ÌÖçÏä§Ìä∏Î°ú TF-IDF Îã®Ïñ¥Ïû•ÏùÑ ÎßåÎì≠ÎãàÎã§ ?!\n",
    "    - TF-IDFÎûÄ Î¨∏ÏÑú ÎÇ¥ Îã®Ïñ¥ ÎπàÎèÑÏàòÏôÄ Îã®Ïñ¥Í∞Ä Îì±Ïû•Ìïú Î¨∏ÏÑú ÎπàÎèÑÏàòÎ•º ÏÇ¨Ïö©ÌïòÏó¨ Î≤°ÌÑ∞Î•º ÏÉùÏÑ±ÌïòÎäî Î∞©Î≤ïÏûÖÎãàÎã§. \n",
    "4. ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ÏÑ∏Ìä∏Ïùò TF-IDF Îã®Ïñ¥Ïû•ÏúºÎ°ú ÌïôÏäµÏö© Îç∞Ïù¥ÌÑ∞ÏÑ∏Ìä∏ÏôÄ ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ÏÑ∏Ìä∏Î•º Î≤°ÌÑ∞Ìôî ÏãúÌÇµÎãàÎã§.\n",
    "5. ML ClassifierÍ∞Ä ÏûÖÎ†•ÏúºÎ°ú Î∞õÎäî Î≤°ÌÑ∞Îäî ÌÖåÏä§Ìä∏ÏÖãÏùò Îã®Ïñ¥Îì§Ïóê ÎåÄÌïú ÌïôÏäµÏö© ÌÖçÏä§Ìä∏Îì§Ïùò TF-IDF Í∞íÏù¥ Îê©ÎãàÎã§.\n",
    "6. ML ClassifierÎäî Ï†ÑÎã¨Î∞õÏùÄ ÌÖçÏä§Ìä∏ ÎÇ¥Ïóê ÌÖåÏä§Ìä∏ ÏÑ∏Ìä∏Ïùò Îã®Ïñ¥Í∞Ä ÏñºÎßàÎÇò Ìè¨Ìï®ÎêòÏñ¥ ÏûàÎäîÏßÄÎ•º Î≤°ÌÑ∞Ìôî Ìïú Í∞íÏúºÎ°ú Ïù∏ÏãùÌïòÍ≥† Ìå®ÌÑ¥ÏùÑ ÌïôÏäµÌï©ÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_special_tokens():\n",
    "    return {\"unknown\": \"[UNK]\", \"padding\": \"[PAD]\", \"mask\": \"[MASK]\", \"cls\": \"[CLS]\", \"sep\": \"[SEP]\"}\n",
    "\n",
    "\n",
    "def get_raw_bpe_tokenizer(corpus: List[str], num_words: int = VOCAB_SIZE, lowercase: bool = LOWERCASE) -> Tokenizer:\n",
    "    logger = create_logger('get_raw_bpe_tokenizer')\n",
    "\n",
    "    # initialize tokenizer\n",
    "    logger.info(\"Initializing tokenizer...\")\n",
    "    special_tokens = get_special_tokens()\n",
    "    bpe_model = models.BPE(unk_token=special_tokens[\"unknown\"])\n",
    "    raw_tokenizer = Tokenizer(model=bpe_model)\n",
    "\n",
    "    # set normalizer\n",
    "    logger.info(\"Setting normalizer...\")\n",
    "    _normalizers = [normalizers.NFC()]\n",
    "    if lowercase:\n",
    "        _normalizers.append(normalizers.Lowercase())\n",
    "    raw_tokenizer.normalizer = normalizers.Sequence(_normalizers)\n",
    "    raw_tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel()\n",
    "    \n",
    "    # training\n",
    "    logger.info(\"Setting trainer...\")\n",
    "    _special_tokens = list(special_tokens.values())\n",
    "    trainer = trainers.BpeTrainer(\n",
    "        vocab_size=num_words,\n",
    "        special_tokens=_special_tokens,\n",
    "    )\n",
    "    dataset = Dataset.from_dict({\"text\": corpus})\n",
    "\n",
    "    def _training_corpus_iterator():\n",
    "        for i in range(0, len(dataset), 1000):\n",
    "            yield list(dataset[\"text\"][i : i + 1000])\n",
    "\n",
    "    logger.info(\"Training tokenizer...\")\n",
    "    raw_tokenizer.train_from_iterator(_training_corpus_iterator(), trainer=trainer)\n",
    "    tokenizer = PreTrainedTokenizerFast(\n",
    "        tokenizer_object=raw_tokenizer,\n",
    "        unk_token=special_tokens[\"unknown\"],\n",
    "        pad_token=special_tokens[\"padding\"],\n",
    "        mask_token=special_tokens[\"mask\"],\n",
    "        cls_token=special_tokens[\"cls\"],\n",
    "        sep_token=special_tokens[\"sep\"]\n",
    "    )\n",
    "    logger.info(\"Done!\")\n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "def get_tf_idf_vectors(tokenized_texts_train: List[List[str]], tokenized_texts_test: List[List[str]]):\n",
    "    logger = create_logger('get_tf_idf_vectors')\n",
    "\n",
    "    logger.info(\"Initializing TF-IDF vectorizer for test samples ...\")\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        ngram_range=(3, 5), \n",
    "        lowercase=False, \n",
    "        sublinear_tf=True,\n",
    "        analyzer='word',\n",
    "        tokenizer=lambda x: x,\n",
    "        preprocessor=lambda x: x,\n",
    "        token_pattern=None, \n",
    "        strip_accents='unicode'\n",
    "    )\n",
    "    logger.info(\"Fitting TF-IDF vectorizer using test samples ...\")\n",
    "    vectorizer.fit(tokenized_texts_test)\n",
    "    vocab = vectorizer.vocabulary_\n",
    "    logger.info(f\"Number of words in TF-IDF vocabulary: {len(vocab)}\")\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(\n",
    "        ngram_range=(3, 5), \n",
    "        lowercase=False, \n",
    "        sublinear_tf=True, \n",
    "        vocabulary=vocab,\n",
    "        analyzer='word',\n",
    "        tokenizer=lambda x: x,\n",
    "        preprocessor=lambda x: x,\n",
    "        token_pattern=None, \n",
    "        strip_accents='unicode'\n",
    "    )\n",
    "\n",
    "    logger.info(\"Transforming train texts...\")\n",
    "    train_vectors = vectorizer.fit_transform(tokenized_texts_train)\n",
    "    logger.info(\"Transforming test texts...\")\n",
    "    test_vectors = vectorizer.transform(tokenized_texts_test)\n",
    "    \n",
    "    logger.info(f\"Shape of train vectors: {train_vectors.shape}\")\n",
    "    logger.info(f\"Shape of test vectors: {test_vectors.shape}\")\n",
    "    return train_vectors, test_vectors\n",
    "\n",
    "\n",
    "def ensemble_baseline(X, y, X_test):\n",
    "    clf = MultinomialNB(alpha=0.02)\n",
    "    sgd_model = SGDClassifier(max_iter=8000, tol=1e-4, loss=\"modified_huber\") \n",
    "    weights = [0.5, 0.5]\n",
    "    ensemble = VotingClassifier(\n",
    "        estimators=[('mnb',clf), ('sgd', sgd_model)],\n",
    "        weights=weights, \n",
    "        voting='soft', \n",
    "        n_jobs=-1\n",
    "    )\n",
    "    ensemble.fit(X, y)\n",
    "    y_pred = ensemble.predict_proba(X_test)[:, 1]\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:get_raw_bpe_tokenizer:Initializing tokenizer...\n",
      "INFO:get_raw_bpe_tokenizer:Setting normalizer...\n",
      "INFO:get_raw_bpe_tokenizer:Setting trainer...\n",
      "INFO:get_raw_bpe_tokenizer:Training tokenizer...\n",
      "INFO:get_raw_bpe_tokenizer:Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "575c56890dc24bc983c83ca3a943ddc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ec9215ecb349aa8e52d882b1b7104d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44868 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = get_raw_bpe_tokenizer(test_essays_df['text'].tolist())\n",
    "tokenized_texts_test = []\n",
    "tokenized_texts_train = []\n",
    "\n",
    "for text in tqdm(test_essays_df['text'].tolist()):\n",
    "    tokenized_texts_test.append(tokenizer.tokenize(text))\n",
    "\n",
    "for text in tqdm(train_v2_drcat_df['text'].tolist()):\n",
    "    tokenized_texts_train.append(tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:get_tf_idf_vectors:Initializing TF-IDF vectorizer for test samples ...\n",
      "INFO:get_tf_idf_vectors:Fitting TF-IDF vectorizer using test samples ...\n",
      "INFO:get_tf_idf_vectors:Number of words in TF-IDF vocabulary: 9\n",
      "INFO:get_tf_idf_vectors:Transforming train texts...\n",
      "INFO:get_tf_idf_vectors:Transforming test texts...\n",
      "INFO:get_tf_idf_vectors:Shape of train vectors: (44868, 9)\n",
      "INFO:get_tf_idf_vectors:Shape of test vectors: (3, 9)\n"
     ]
    }
   ],
   "source": [
    "tf_train, tf_test = get_tf_idf_vectors(tokenized_texts_train, tokenized_texts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39345228, 0.39345228, 0.39345228])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_baseline = ensemble_baseline(X=tf_train, y=train_v2_drcat_df['label'].to_list(), X_test=tf_test)\n",
    "pred_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_df[\"generated\"] = pred_baseline\n",
    "sample_submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
